{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Malaria Project\n",
    "\n",
    "## Introduction \n",
    "##### Members\n",
    "   Sebastian Schwarz\n",
    "   Youssef Hantous\n",
    "\n",
    "##### Project Description\n",
    "The aim of this project is to study the distribution and evolution of anophenile vectors of Malaria in Africa. \n",
    "The dataset is a compilation of all available mosquito studies from 1898 to 2016. It was compiled in *Kyalo D, Amratia P, Mundia CW et al. A geo-coded inventory of anophelines in the Afrotropical Region south of the Sahara: 1898-2016*, published in 2017 with the help of the KEMRI-Wellcome Trust, in collaboration with many major research agencies on Malaria. \n",
    "\n",
    "This data should help better understand how malaria developped in the past century and what species are primarily associated with its expansion. \n",
    "\n",
    "We want to present this data in a clear fashion, showing trends in the evolution and the spread of anopheniles in Africa, and try to predict the future repartition of main malaria transmitting species. \n",
    "\n",
    "\n",
    "##### Data Source \n",
    "- Kaggle: https://www.kaggle.com/jboysen/malaria-mosquito \n",
    "- Dataverse: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NQ6CUN\n",
    "\n",
    "The paper describing how this dataset was compiled can be found here: https://wellcomeopenresearch.org/articles/2-57/v1 \n",
    "\n",
    "##### Github Repository\n",
    "- https://github.com/SebastianS09/Malaria (peut être pas) \n",
    "\n",
    "\n",
    "## Code\n",
    "#### Data Import auditing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "data_raw = pd.read_csv(\"https://raw.githubusercontent.com/SebastianS09/Malaria/master/Data/Malaria.csv\")\n",
    "\n",
    "print(\"The dataset has \",data_raw.shape[0],\"rows and \",data_raw.shape[1],\"columns\")\n",
    "\n",
    "data_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One observation of the data set is associated with one location, time and a source study. \n",
    "The location information is displayed as follows: \n",
    "- Country and Village name\n",
    "- GAUL administrative regions (https://en.wikipedia.org/wiki/Global_Administrative_Unit_Layers) which are a unified spatial admnistrative unit system\n",
    "- Geospatial coordinates and source\n",
    "\n",
    "Each survey has a start and an end date. We will audit this in the next cell\n",
    "\n",
    "There is supplementary information on the survey namely:\n",
    "- Adults/Larvae: whether the survey was conducts on adults or larvae (live in water), sometimes unknown\n",
    "- Sampling methods: how the speciemens where caught \n",
    "- Identification methods: how they were attributed to one species\n",
    "- Other names and other species: if the species found also have other names and if they were other species present than the main 36 quoted\n",
    "Details of the abreviations can be found here: https://github.com/SebastianS09/Malaria/blob/master/Data/Africa%20Vectors%20database_1898-2016_key.pdf\n",
    "\n",
    "We will explore this supplementary information later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#increasing size of graphs\n",
    "mp.rcParams['figure.dpi'] = 72*2\n",
    "\n",
    "dates = np.vstack([data_raw[\"YeStart\"],data_raw[\"YeEnd\"]]).T\n",
    "plt.hist(dates,bins=50, alpha=0.75, label=['Start', 'End'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Histogram of survey Start and End year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most of the surveys have been executed around the 60s and in the late 2000s. \n",
    "\n",
    "However, the start year and the end year do not always coincide, meaning that the surveys may have been run on periods extending one year. Let us look into this with more detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = dates[:,1]-dates[:,0]\n",
    "plt.hist(length, bins=50, facecolor=\"blue\", alpha=0.75)\n",
    "plt.title(\"Histogram of Survey length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the surveys have lasted for less than five years which seems reasonable. \n",
    "The fact that there is a non zero number of surveys lasting more than 20 years however is surprising. \n",
    "Let us look at this data and query the unique study titles associated to these long period surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long_survey = data_raw[[\"YeStart\",\"YeEnd\",\"Source_Title\"]].query(\"YeEnd-YeStart>20\")\n",
    "pd.DataFrame(long_survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(long_survey[\"Source_Title\"].value_counts().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this summary data, it seems that republication dates have sometimes be taken into account as end dates (see Hamon J studies for example). \n",
    "\n",
    "**Moving forward, we will therefore use the start date as the reference date.** We would suggest auditing these long period cases for the sake of the datasets integrity, even if it does not affect us very much here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us move forward and clean the data to only keep the rows we need in our anlaysis. \n",
    "\n",
    "##### Removing unecessary geographical precision and study information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw.columns = [i.replace(' ', '_') for i in data_raw.columns]\n",
    "col_rm = ['GAUL_Admin2','Full_Name','LatLong_Source','Source_Title']\n",
    "data_rm = data_raw.drop(col_rm, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning Adults/Larvae field for Case\n",
    "\n",
    "We notice that we have an occurence of Adults/larvae with a minuscule which we want to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw[\"Adults/Larvae\"] = data_raw[\"Adults/Larvae\"].replace(\"Adults, larvae\",\"Adults, Larvae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacing Y and NaN with 0 and 1 for ease of understanding (col 7 to 33)\n",
    "As we can see, the presence of an anophenile is encoded in columns holding the species' names, with \"Yes\" if it is present and \"NaN\" otherwise. \n",
    "We will replace these values to 0 and 1 to be able to perform mathematical operations on the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clean = data_rm.copy()\n",
    "\n",
    "ano = list(data_clean)[6:32]\n",
    "data_clean[ano] = data_clean[ano].replace(['Y'],1)\n",
    "data_clean[ano] = data_clean[ano].fillna(0)\n",
    "\n",
    "data_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Editing Other Species\n",
    "We see that we have other species not mentionned in the column names in the last column. Let us check if they are relevant (in terms of frequency vs. species with dedicated columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting the last column as the additional are comma separated\n",
    "other_f = data_clean['Other_Anopheline_species'].str.split(', ', expand=True)\n",
    "other_f.fillna(0,inplace=True)\n",
    "\n",
    "#counting the occurence in each new column\n",
    "a = other_f[0].value_counts().to_frame()\n",
    "for i in list(other_f.drop(0,axis=1)):\n",
    "    a = a.join(other_f[i].value_counts().to_frame())\n",
    "a.fillna(0,inplace=True)\n",
    "\n",
    "#summing the columns up to have a definite count\n",
    "pd.DataFrame(a.sum(axis=1).sort_values(ascending = False)[1:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data_clean[ano].sum(axis=0).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are quite high occuring species in \"Others\". they would rank above An Mouscheti in the primary vector classification. \n",
    "\n",
    "However, and as stated in the abstract, the classification has not be done exclusively on occurence. According to the authors of the dataset, *\"The definition of secondary vectors is complex and often site/time specific\"* We refer to the paper for further information but the main point is that secondary vectors do not transmit paludism to humans, or in very rare cases. \n",
    "\n",
    "For the sake of the exercise and reflecting information of this databse of anopheniles: http://bioinfo-web.mpl.ird.fr/identiciels/anopheles/html/taxa/pretoriensis_A_.html, we will add  An Pretoriensis to the primary vectors as they have been transmitting fever generating arboviruses in Nigeria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "An_pretoriensis = data_clean[\"Other_Anopheline_species\"].str.contains(\"An pretoriensis\").fillna(0)*1\n",
    "data_clean.insert(32,\"An_pretoriensis\",An_pretoriensis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MetaData analysis\n",
    "Let us explore the metadata associated to the records which is:\n",
    "- Adults/Larvae\n",
    "- Sampling_Methods\n",
    "- Species_Identification\n",
    "\n",
    "We will start with some quick summarizing and plotting\n",
    "\n",
    "##### Species type survey Attributes in time and Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = data_raw[[\"YeStart\",\"Adults/Larvae\"]]\n",
    "AL_pivot = AL.reset_index().pivot_table(index = \"YeStart\", columns = \"Adults/Larvae\",aggfunc=lambda x: len(x.unique())).fillna(0)\n",
    "AL_pivot.columns = AL_pivot.columns.droplevel()\n",
    "\n",
    "x = AL_pivot.index.values\n",
    "y = np.vstack(AL_pivot[i] for i in AL_pivot.columns)\n",
    "y_norm = (y/y.sum(axis=0))\n",
    "lbs = list(AL_pivot)\n",
    "\n",
    "test = pd.DataFrame(y_norm.T,columns=lbs)\n",
    "test.index = x\n",
    "test.plot.bar(stacked = True)\n",
    "\n",
    "#ax = plt.subplot(111)\n",
    "#ax.bar(x-0.2, y[0],width=0.1,color='b',align='center', label = AL_pivot.columns[0])\n",
    "#ax.bar(x-0.1, y[1],width=0.1,color='g',align='center',label = AL_pivot.columns[1])\n",
    "#ax.bar(x+0.1, y[2],width=0.1,color='r',align='center',label = AL_pivot.columns[2])\n",
    "#ax.bar(x+0.2, y[3],width=0.1,color='y',align='center',label = AL_pivot.columns[3])\n",
    "\n",
    "ax = plt.gca() \n",
    "ax.set_xticks(range(2,120,10))\n",
    "ax.set_xticklabels(range(1900,2020,10))\n",
    "\n",
    "plt.legend(loc='upper left',ncol=4, mode=\"expand\")\n",
    "plt.title(\"Bar Chart of survey type\")\n",
    "plt.ylim(ymax = 1.2, ymin = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that over time, surveys focused in particular on Adults but also Larvae are prefered over mixed surveys. This makes sense as it must be easier to distinguish species and to make more accurate surveys. \n",
    "Also, Unknown survey tend to diminish over time, due to better reporting\n",
    "\n",
    "Let us check if there is a geographical influence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate breaks in a sorted daataframe\n",
    "def get_lim(df,col):\n",
    "    val=df[col].unique()\n",
    "    temp = []\n",
    "    temp_s = [0]\n",
    "    out = []\n",
    "    for i in range(0,len(val)):\n",
    "        temp.append(len(df[df[col]==val[i]]))\n",
    "    for i in range(0,len(val)):\n",
    "        temp_s.append(sum(temp[0:i+1]))\n",
    "    for i in range(0,len(val)):\n",
    "        out.append((temp_s[i],temp_s[i+1]))\n",
    "    return(out)    \n",
    "\n",
    "#function to generate colormaps\n",
    "\n",
    "import colorsys\n",
    "\n",
    "def get_N_HexCol(N=5):\n",
    "    HSV_tuples = [(x * 1.0 / N, 0.9, 0.9) for x in range(N)]\n",
    "    hex_out = []\n",
    "    for rgb in HSV_tuples:\n",
    "        rgb = map(lambda x: int(x * 255), colorsys.hsv_to_rgb(*rgb))\n",
    "        hex_out.append('#%02x%02x%02x' % tuple(rgb))\n",
    "    return hex_out\n",
    "\n",
    "get_N_HexCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_G = data_raw[data_raw[\"YeStart\"]>1960][[\"Adults/Larvae\",\"Lat\",\"Long\"]]\n",
    "AL_G = AL_G.sort_values([\"Adults/Larvae\"])\n",
    "\n",
    "limits = get_lim(AL_G,\"Adults/Larvae\")\n",
    "colors = [\"rgb(0,116,217)\",\"rgb(255,65,54)\",\"rgb(133,20,75)\",\"rgb(255,133,27)\"]\n",
    "cities = []\n",
    "names=lbs\n",
    "\n",
    "for i in range(len(limits)):\n",
    "    lim = limits[i]\n",
    "    df_sub = AL_G[lim[0]:lim[1]]\n",
    "    city = dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'africa',\n",
    "        lon = df_sub['Long'],\n",
    "        lat = df_sub['Lat'],\n",
    "#       text = df_sub['text'],\n",
    "        marker = dict(\n",
    "         #   size = df_sub['pop']/scale,\n",
    "            color = colors[i],\n",
    "            line = dict(width=0.5, color='rgb(40,40,40)'),\n",
    "            sizemode = 'area'\n",
    "        ),\n",
    "        #name = '{0} - {1}'.format(lim[0],lim[1]) )\n",
    "        name=names[i] )\n",
    "\n",
    "        \n",
    "    cities.append(city)\n",
    "\n",
    "    \n",
    "layout = dict(\n",
    "        title = 'Distribution de la Malaria au fil des années',\n",
    "        showlegend = True,\n",
    "        geo = dict(\n",
    "            scope='africa',\n",
    "            projection=dict( type='africa' ),\n",
    "            showland = True,\n",
    "            landcolor = 'rgb(185, 185, 185)',\n",
    "            subunitwidth=1,\n",
    "            countrywidth=1,\n",
    "            subunitcolor=\"rgb(200, 200, 200)\",\n",
    "            countrycolor=\"rgb(255, 255, 255)\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=cities, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='bubble-map-populations' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a Geographical perspective, there appears to be no particular preference of survey type since the sixties. \n",
    "Plotting before the sixties show that surveys conducted in central Africa tend to have more Unknowns. \n",
    "\n",
    "\n",
    "##### Sampling Methods\n",
    "\n",
    "Let us compute the top 10 sampling methods\n",
    "\n",
    "Here the abreviations as a reminder:\n",
    "\n",
    "<table class=\"tableizer-table\">\n",
    "<thead><tr class=\"tableizer-firstrow\"><th>Abreviation</th><th>Description</th></tr></thead><tbody>\n",
    " <tr><td>ABC</td><td>Animal Bait Catches</td></tr>\n",
    " <tr><td>Bednet traps</td><td>Bed net traps</td></tr>\n",
    " <tr><td>CDC Light traps</td><td>CDC light traps</td></tr>\n",
    " <tr><td>HBC/NBC</td><td>Human/Night Bait Catches (may be witnin a double sided net)</td></tr>\n",
    " <tr><td>HLC</td><td>Human Landing Catches </td></tr>\n",
    " <tr><td>NBC</td><td>Night Bait Catches</td></tr>\n",
    " <tr><td>IR</td><td>Indoor resting (Often written as room searches, aspirators or hand catches indoors)</td></tr>\n",
    " <tr><td>OS</td><td>Outdoor sampling</td></tr>\n",
    " <tr><td>LC</td><td>Larval Collections</td></tr>\n",
    " <tr><td>Exit traps</td><td>Exit traps</td></tr>\n",
    " <tr><td>PSC </td><td>Pyrethrum Spray Catches</td></tr>\n",
    " <tr><td>ITT </td><td>Ifakara Tent Traps</td></tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_methods = pd.DataFrame(pd.Series(' '.join(data_clean['Sampling_Methods']+\",\").split(\", \")).value_counts()[:10], columns = [\"Count\"])\n",
    "\n",
    "#let us check the evolution of the top 3 cathing methods over time \n",
    "\n",
    "M0 = data_clean[data_clean['Sampling_Methods'].str.match(top_methods.index[0])][\"YeStart\"]\n",
    "M1 = data_clean[data_clean['Sampling_Methods'].str.match(top_methods.index[1])][\"YeStart\"]\n",
    "M2 = data_clean[data_clean['Sampling_Methods'].str.match(top_methods.index[2])][\"YeStart\"]\n",
    "MU = data_clean[data_clean['Sampling_Methods'].str.match(\"Unknown\")][\"YeStart\"]\n",
    "\n",
    "\n",
    "M0v = M0.value_counts()\n",
    "M1v = M1.value_counts()\n",
    "M2v = M2.value_counts()\n",
    "MUv = MU.value_counts()\n",
    "\n",
    "conc = pd.concat([M0v,M1v,M2v,MUv],axis=1)\n",
    "conc.columns=[top_methods.index[[0,1,2,4]]]\n",
    "conc.plot.bar(stacked=True)\n",
    "\n",
    "ax = plt.gca() \n",
    "ax.set_xticks(range(2,120,10))\n",
    "ax.set_xticklabels(range(1900,2020,10))\n",
    "plt.title(\"Bar Chart of collection method\")\n",
    "plt.ylim(ymax = 300, ymin = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a diminution of \"Unknown\" methods over time, again due to better accountability\n",
    "\n",
    "Larval collection is on the rise in the 2000s, after having been used in the 50s and the 60s\n",
    "In-house capture seems to be the more and more used (makes sense as the propagation of malaria is mainly due to anopheniles that attack humans inside their houses)\n",
    "\n",
    "However, there is a prevalence of mixed methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_occ = pd.DataFrame([data_clean[\"Sampling_Methods\"],data_clean[\"Sampling_Methods\"].str.count(\", \")+1]).T\n",
    "\n",
    "multiple_occ.columns = [\"Sampling_Methods\",\"Number of Methods\"]\n",
    "multiple_occ.groupby([\"Number of Methods\"]).count().plot.bar()\n",
    "plt.title(\"Number of sampling methods used per survey\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, more than half the surveys are using at least two methods. \n",
    "\n",
    "##### Focus on species indentification\n",
    "\n",
    "Let us see now how species have been identified. As a reminder, the list of abreviations: \n",
    "\n",
    "<table class=\"tableizer-table\">\n",
    "<thead><tr class=\"tableizer-firstrow\"><th>Species ID method</th><th>Description</th></tr></thead><tbody>\n",
    " <tr><td>CBS</td><td>Chromosone Banding </td></tr>\n",
    " <tr><td>DNA</td><td>Sequencing DNA probes</td></tr>\n",
    " <tr><td>M </td><td>Morphology</td></tr>\n",
    " <tr><td>PCR</td><td>Polymerase Chain Reaction</td></tr>\n",
    "</tbody></table>\n",
    "\n",
    "We have only four methods, but a combination of methods can be used: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_id = pd.DataFrame([data_clean[\"Species_Identification\"],data_clean[\"Species_Identification\"].str.count(\", \")+1]).T\n",
    "\n",
    "multiple_id.columns = [\"Species_Identification\",\"Number of Methods\"]\n",
    "multiple_id.groupby([\"Number of Methods\"]).count().plot.bar()\n",
    "plt.title(\"Number of identification methods used per survey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, roughly half the surveys have at least two id methods. \n",
    "\n",
    "Does this change over time ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_id = pd.DataFrame([data_clean[\"YeStart\"],data_clean[\"Species_Identification\"].str.count(\", \")+1]).T\n",
    "mean_id.columns = [\"YeStart\",\"Number of Methods\"]\n",
    "mean_id.groupby([\"YeStart\"])[\"Number of Methods\"].mean().plot()\n",
    "plt.title(\"Mean number of identification methods over time\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a slight positive trend from 1 to 2 identification methods between 1960 and 2000. Between 1900 and 1930, there is quite a high volatility in the number of methods used. The value in 1918 is surprising as DNA sequencing was not available at this point (starts in the 80s as we can see on the graph)\n",
    "\n",
    "**Further inspection on these surprising data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_dna  = pd.DataFrame([data_clean[\"YeStart\"],data_clean[\"Species_Identification\"],data_clean[\"Species_Identification\"].str.count(\", \")+1,data_raw[\"Source_Title\"]]).T\n",
    "early_dna.columns= [\"YeStart\",\"Species_Identification\",\"Count\",\"Source_Title\"]\n",
    "early_dna[(early_dna[\"Species_Identification\"].str.contains(\"DNA\")) & (early_dna[\"YeStart\"]<1950)].sort_values(\"YeStart\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a limited number of studies mentionning DNA as a source before the 50s. \n",
    "This would be worth having a look into, and determining what exactly was ment. \n",
    "\n",
    "Here is the list of the studies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_early_dna = early_dna[(early_dna[\"Species_Identification\"].str.contains(\"DNA\")) & (early_dna[\"YeStart\"]<1940)].sort_values(\"YeStart\")\n",
    "\n",
    "values_early_dna[\"Source_Title\"].str.slice(0,50).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These studies would be worth looking into, in particular Kumm HW and Symes CB as they account for 16 of the occurences. \n",
    "\n",
    "Let us check now what method is the prefered method when only one is chosen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_id = pd.DataFrame([data_clean[\"Species_Identification\"],data_clean[\"Species_Identification\"].str.count(\", \")+1]).T\n",
    "single_id.columns = [\"Species_Identification\",\"Number of Methods\"]\n",
    "single_id_out = single_id[single_id[\"Number of Methods\"] == 1]\n",
    "single_id_out.groupby([\"Species_Identification\"]).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time a single method has been used (roughly 50% of studies), it was a morphological analysis. \n",
    "\n",
    "As such, it is confirmed that other methods come on top to validate this morphological approach. \n",
    "\n",
    "Let us check the percent of single morphological studies over time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_id = pd.DataFrame([data_clean[\"YeStart\"],data_clean[\"Species_Identification\"],data_clean[\"Species_Identification\"].str.count(\", \")+1]).T\n",
    "single_id.columns = [\"YeStart\",\"Species_Identification\",\"Number of Methods\"]\n",
    "single_id_out = single_id[single_id[\"Number of Methods\"] == 1]\n",
    "\n",
    "single_count = single_id_out.groupby([\"YeStart\"]).sum()[\"Number of Methods\"]\n",
    "total_count = data_clean[\"YeStart\"].value_counts()\n",
    "\n",
    "out = pd.concat([single_count,total_count],axis=1)\n",
    "out.columns = [\"single\",\"total\"]\n",
    "\n",
    "out_p = out.single/out.total\n",
    "out_p.plot()\n",
    "plt.title(\"Fraction of single test surveys over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend is clearly decreasing, indicating that as time goes by, scientist have been more and more using multiple methods to identify anophenile vectore in Africa. \n",
    "\n",
    "Let us have a look at the geography of the identification methods, to see, again if there is a preference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_G = data_raw[data_raw[\"YeStart\"]>1960][[\"Species_Identification\",\"Lat\",\"Long\"]]\n",
    "\n",
    "M_G = M_G.sort_values([\"Species_Identification\"])\n",
    "M_G_s = M_G.copy()\n",
    "M_G_s.Species_Identification = M_G.Species_Identification.str.strip(\"M, \")\n",
    "\n",
    "M_G_s = pd.concat([M_G_s,M_G_s.Species_Identification.str.count(\", \")+1],axis=1)\n",
    "\n",
    "M_G_s.columns = [\"Id\",\"Lat\",\"Long\",\"Count\"]\n",
    "M_G_s.Id.replace(\"\",\"M\",inplace=True)\n",
    "\n",
    "M_G_plot = M_G_s[M_G_s[\"Count\"]<2][[\"Id\",\"Lat\",\"Long\"]]\n",
    "M_G_plot = M_G_plot.sort_values([\"Id\"])\n",
    "M_G_plot = M_G_plot[M_G_plot.Id.isin(M_G_plot.Id.value_counts().index[M_G_plot.Id.value_counts()>10].values)]\n",
    "\n",
    "\n",
    "limits = get_lim(M_G_plot,\"Id\")\n",
    "colors = get_N_HexCol(len(limits))\n",
    "cities = []\n",
    "names= M_G_plot.Id.value_counts().index[M_G_plot.Id.value_counts()>10].values\n",
    "\n",
    "for i in range(len(limits)):\n",
    "    lim = limits[i]\n",
    "    df_sub = AL_G[lim[0]:lim[1]]\n",
    "    city = dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'africa',\n",
    "        lon = df_sub['Long'],\n",
    "        lat = df_sub['Lat'],\n",
    "        marker = dict(\n",
    "            color = colors[i],\n",
    "            line = dict(width=0.5, color='rgb(40,40,40)'),\n",
    "            sizemode = 'area'\n",
    "        ),\n",
    "        name=names[i] )\n",
    "\n",
    "        \n",
    "    cities.append(city)\n",
    "\n",
    "    \n",
    "layout = dict(\n",
    "        title = 'Identification methods of anophenile vectore after 1960',\n",
    "        showlegend = True,\n",
    "        geo = dict(\n",
    "            scope='africa',\n",
    "            projection=dict( type='africa' ),\n",
    "            showland = True,\n",
    "            landcolor = 'rgb(185, 185, 185)',\n",
    "            subunitwidth=1,\n",
    "            countrywidth=1,\n",
    "            subunitcolor=\"rgb(200, 200, 200)\",\n",
    "            countrycolor=\"rgb(255, 255, 255)\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=cities, layout=layout )\n",
    "py.iplot( fig, validate=False, filename='bubble-map-populations' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite interesting as it appears some methods have been used very locally, such as the XXX method. \n",
    "Other methods seem to be in use all over Africa with a small number of marginal methods (less than 10 occurences). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inspection tools\n",
    "\n",
    "As a second step we will write some tools (functions), that will allow us to inspect parts of the data, in particular to extract records of the dataset and to present them in a new and interesting fashion\n",
    "\n",
    "- function to get all the mosquitos associated to a country and a time frame\n",
    "- function to get all the records near a given point of interest \n",
    "- function to XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode(\"Nairobi\")\n",
    "print((location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
